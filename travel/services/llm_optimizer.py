# travel/services/llm_optimizer.py
import json
import random
from travel.models import Place
from google import genai  # Gemini API í´ë¼ì´ì–¸íŠ¸
from google.genai.errors import APIError
from dotenv import load_dotenv
import os

# ğŸš¨ğŸš¨ ìˆ˜ì •: .env íŒŒì¼ ê²½ë¡œ ì§€ì • (travel/services/ -> travel/) ğŸš¨ğŸš¨
dotenv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
load_dotenv(dotenv_path=dotenv_path)

# Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ğŸš¨ğŸš¨ ìˆ˜ì •: os.getenv()ì— ë³€ìˆ˜ ì´ë¦„(ë¬¸ìì—´)ì„ ì „ë‹¬ ğŸš¨ğŸš¨
API_KEY = os.getenv("GEMINI_API_KEY") 

if API_KEY:
    try:
        client = genai.Client(api_key=API_KEY)
        LLM_ACTIVE = True
        print("INFO: Gemini Clientê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. LLM ìµœì í™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"WARNING: Gemini Client ì´ˆê¸°í™” ì‹¤íŒ¨ ({e}). Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        LLM_ACTIVE = False
        client = None
else:
    # ì´ ë¡œê·¸ê°€ ë³´ì¸ë‹¤ë©´ .env íŒŒì¼ì˜ GEMINI_API_KEY ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.
    print("WARNING: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ LLM ìµœì í™”ëŠ” Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    LLM_ACTIVE = False
    client = None


def optimize_route_with_llm(places: list) -> list:
    """
    ì„ íƒëœ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìµœì ì˜ ìˆœì„œë¥¼ ë°›ì•„ì™€ ì¬ë°°ì—´í•˜ê±°ë‚˜, 
    ì‹¤íŒ¨ ì‹œ Mock ë°ì´í„°ë¡œ í´ë°±í•©ë‹ˆë‹¤.
    """
    
    place_data = []
    for place in places:
        if isinstance(place, Place):
            place_data.append({
                # JSON ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì´ë¦„ì—ì„œ ì¤„ ë°”ê¿ˆ ë° ê³µë°±ì„ ëª…ì‹œì ìœ¼ë¡œ ì œê±° 
                'name': place.name.replace('\n', ' ').strip(), 
                'lat': place.lat,
                'lon': place.lon
            })
            
    optimized_names = []
    
    if LLM_ACTIVE and client:
        prompt = f"""
        ë‹¹ì‹ ì€ ì—¬í–‰ ë™ì„  ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¥ì†Œë“¤ì˜ ìœ„ë„(lat)ì™€ ê²½ë„(lon)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
        ê°€ì¥ íš¨ìœ¨ì ì¸ ì´ë™ ê²½ë¡œ ìˆœì„œë¥¼ ê²°ì •í•˜ê³ , ê²°ì •ëœ ìˆœì„œëŒ€ë¡œ **ì¥ì†Œ ì´ë¦„(name)** ë¦¬ìŠ¤íŠ¸ë§Œì„ JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        [ì¥ì†Œ ëª©ë¡]
        {json.dumps(place_data, ensure_ascii=False, indent=2)}
        """
        
        try:
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=genai.types.GenerateContentConfig(
                    response_mime_type="application/json", 
                    response_schema={"type": "array", "items": {"type": "string"}}
                )
            )
            
            optimized_names = json.loads(response.text)
            
            valid_names = {p['name'] for p in place_data}
            if not isinstance(optimized_names, list) or not all(name in valid_names for name in optimized_names):
                 raise ValueError("LLM ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            print("INFO: LLMì„ í†µí•´ ê²½ë¡œ ìµœì í™”ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.")
            
        except (APIError, json.JSONDecodeError, ValueError) as e:
            print(f"ğŸš¨ LLM API/íŒŒì‹± ì˜¤ë¥˜ (Mock í´ë°±): {e}")
        except Exception as e:
            print(f"ğŸš¨ ê¸°íƒ€ ì˜¤ë¥˜ (Mock í´ë°±): {e}")


    # LLM í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ë¹„í™œì„±í™”ëœ ê²½ìš°, Mock ë°ì´í„° ë¡œì§ìœ¼ë¡œ í´ë°±
    if not optimized_names:
        print("INFO: Mock ê²½ë¡œ ìˆœì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        cleaned_names = [p['name'] for p in place_data]
        optimized_names = cleaned_names
        if len(optimized_names) > 1:
            random.shuffle(optimized_names[1:])
        
    # ìµœì¢… ë¦¬ìŠ¤íŠ¸ ì¬êµ¬ì„± (ì´ë¦„ í´ë¦¬ë‹ì„ í†µí•´ ë§¤ì¹­)
    name_to_place = {place.name.replace('\n', ' ').strip(): place for place in places}
    optimized_places = []
    
    for name in optimized_names:
        if name in name_to_place:
            optimized_places.append(name_to_place[name])
            
    return optimized_places